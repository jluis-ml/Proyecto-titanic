{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///backend.db\")\n",
    "mlflow.set_experiment(\"Experimento_3\")\n",
    "\n",
    "with mlflow.start_run(run_name = \"example_1\"):\n",
    "\n",
    "    X,y = load_iris(return_X_y= True)\n",
    "    params = {\"C\": 0.1, \"random_state\": 42}\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    lr = LogisticRegression(**params).fit(X, y)\n",
    "    y_pred = lr.predict(X)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y, y_pred))\n",
    "    mlflow.sklearn.log_model(lr, artifact_path=\"models\")\n",
    "    print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probaremos que hacen las funciones que hay en el repositorio de Mlops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix, \n",
    "                             ConfusionMatrixDisplay, precision_recall_fscore_support, \n",
    "                             precision_score, recall_score, roc_auc_score)\n",
    "import logging\n",
    "\n",
    "# Configura el logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name: str, path=\"D:/Repositorio/Proyecto-titanic/Notebooks\") -> pd.DataFrame:\n",
    "    return pd.read_csv(os.path.join(path, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_what_happened</th>\n",
       "      <th>ticket_classification</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>relevant_topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good morning my name is XXXX XXXX and I apprec...</td>\n",
       "      <td>Debt collection + Credit card debt</td>\n",
       "      <td>morning nam bank cardmemb servic i debt verifi...</td>\n",
       "      <td>Mortgage/Loan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I upgraded my XXXX XXXX card in XX/XX/2018 and...</td>\n",
       "      <td>Credit card or prepaid card + General-purpose ...</td>\n",
       "      <td>i card agent upgrad dat agent information orde...</td>\n",
       "      <td>Mortgage/Loan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chase Card was reported on XX/XX/2019. However...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>card report howev application hav identity con...</td>\n",
       "      <td>Mortgage/Loan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On XX/XX/2018, while trying to book a XXXX  XX...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>book ticket offer ticket card i information of...</td>\n",
       "      <td>Mortgage/Loan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my grand son give me check for {$1600.00} i de...</td>\n",
       "      <td>Checking or savings account + Checking account</td>\n",
       "      <td>giv check deposit chas account fund cle bank c...</td>\n",
       "      <td>Bank Account Services</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             complaint_what_happened  \\\n",
       "0  Good morning my name is XXXX XXXX and I apprec...   \n",
       "1  I upgraded my XXXX XXXX card in XX/XX/2018 and...   \n",
       "2  Chase Card was reported on XX/XX/2019. However...   \n",
       "3  On XX/XX/2018, while trying to book a XXXX  XX...   \n",
       "4  my grand son give me check for {$1600.00} i de...   \n",
       "\n",
       "                               ticket_classification  \\\n",
       "0                 Debt collection + Credit card debt   \n",
       "1  Credit card or prepaid card + General-purpose ...   \n",
       "2  Credit reporting, credit repair services, or o...   \n",
       "3  Credit reporting, credit repair services, or o...   \n",
       "4     Checking or savings account + Checking account   \n",
       "\n",
       "                                      processed_text        relevant_topics  \n",
       "0  morning nam bank cardmemb servic i debt verifi...          Mortgage/Loan  \n",
       "1  i card agent upgrad dat agent information orde...          Mortgage/Loan  \n",
       "2  card report howev application hav identity con...          Mortgage/Loan  \n",
       "3  book ticket offer ticket card i information of...          Mortgage/Loan  \n",
       "4  giv check deposit chas account fund cle bank c...  Bank Account Services  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickets = read_data(\"tickets_inputs_eng_1.csv\")\n",
    "tickets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transform(data:pd.DataFrame):\n",
    "    X = tickets[\"processed_text\"]\n",
    "    y = tickets[\"relevant_topics\"]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding2(data, columns):\n",
    "    encoded_data = pd.get_dummies(data, columns=columns, drop_first=True)\n",
    "    return encoded_data.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>887 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Age  Siblings/Spouses Aboard  Parents/Children Aboard  Fare  \\\n",
       "0         3   22                        1                        0     7   \n",
       "1         1   38                        1                        0    71   \n",
       "2         3   26                        0                        0     7   \n",
       "3         1   35                        1                        0    53   \n",
       "4         3   35                        0                        0     8   \n",
       "..      ...  ...                      ...                      ...   ...   \n",
       "882       2   27                        0                        0    13   \n",
       "883       1   19                        0                        0    30   \n",
       "884       3    7                        1                        2    23   \n",
       "885       1   26                        0                        0    30   \n",
       "886       3   32                        0                        0     7   \n",
       "\n",
       "     Sex_male  \n",
       "0           1  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           1  \n",
       "..        ...  \n",
       "882         1  \n",
       "883         0  \n",
       "884         0  \n",
       "885         1  \n",
       "886         1  \n",
       "\n",
       "[887 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoding2(X, [\"Sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_idx2label(json_path: str) -> pd.Series:\n",
    "    \"\"\"This function read the json file and return a dictionary\n",
    "    Args:\n",
    "      json_path (str): path to the json file\n",
    "     Returns:\n",
    "      idx2label (dict): dictionary with the mapping\"\"\"\n",
    "    with open(json_path) as f:\n",
    "        idx2label = json.load(f)\n",
    "    return idx2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_labels_into_idx(labels: pd.Series, idx2label: dict) -> pd.Series:\n",
    "    \"\"\"This function decode the labels into idx\n",
    "    Args:\n",
    "      labels (pd.Series): series with the labels\n",
    "      idx2label (dict): dictionary with the mapping\n",
    "     Returns:\n",
    "      labels (pd.Series): series with the labels decoded\n",
    "    \"\"\"\n",
    "    return labels.map(idx2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_transform(X: pd.Series) -> np.ndarray:\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    X_vectorized = count_vectorizer.fit_transform(X)\n",
    "    #save count vectorizer for data preprocessing in the main app (deploy)\n",
    "    joblib.dump(count_vectorizer, 'D:/Repositorio/Proyecto-titanic/Notebooks/data_processed/count_vectorizer.pkl')\n",
    "    logger.info(\"count vectorizer trained successfully stored\")\n",
    "    return X_vectorized\n",
    "\n",
    "\n",
    "def transform_tfidf(X_vectorized: object) -> np.ndarray:\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    X_tfidf = tfidf_transformer.fit_transform(X_vectorized)\n",
    "    joblib.dump(X_tfidf, 'D:/Repositorio/Proyecto-titanic/Notebooks/data_processed/X_tfidf.pkl')\n",
    "    logger.info(\"X_tfidf trained successfully stored\")\n",
    "    return X_tfidf\n",
    "\n",
    "def save_pickle(data, filename) -> None:\n",
    "    \"\"\"\n",
    "    This function saves the data in a pickle file\n",
    "    Args:\n",
    "        data (object): data to save\n",
    "        filename (str): filename\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(\"D:/Repositorio/Proyecto-titanic/Notebooks\", \"data_processed\", f\"{filename}.pkl\")\n",
    "    with open(filepath, 'wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "\n",
    "def split_train_test(\n",
    "    X_tfidf: np.array, y: pd.Series, test_size: float = 0.3, random_state: int = 42\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    This function splits the data into train and test\n",
    "    Args:\n",
    "      X_tfidf (np.array): array with the vectorized data\n",
    "      y (pd.Series): series with the labels\n",
    "      test_size (float): test size\n",
    "      random_state (int): random state\n",
    "    Returns:\n",
    "      X_train (np.array): array with the vectorized data for train\n",
    "      X_test (np.array): array with the vectorized data for test\n",
    "      y_train (pd.Series): series with the labels for train\n",
    "      y_test (pd.Series): series with the labels for test\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_tfidf, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    save_pickle((X_train, y_train), \"train\")\n",
    "    save_pickle((X_test, y_test),  \"test\")\n",
    "    logger.info(\"data saved successfully in pickle files\")\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_json= read_idx2label(json_path=\"topic_mapping_1.json\")\n",
    "label_tikets = {value: key for key, value in data_json.items()}\n",
    "X, y = data_transform(tickets)\n",
    "y = decode_labels_into_idx(labels=y, idx2label=label_tikets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:count vectorizer trained successfully stored\n"
     ]
    }
   ],
   "source": [
    "X_vectorized = fit_transform(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:X_tfidf trained successfully stored\n"
     ]
    }
   ],
   "source": [
    "X_tfidf = transform_tfidf(X_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:data saved successfully in pickle files\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = split_train_test(X_tfidf, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
